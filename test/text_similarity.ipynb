{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ì˜¤í”ˆì†ŒìŠ¤ í…ŒìŠ¤íŠ¸\n",
    "paraphrase-MiniLM-L6-v2\n",
    "- ê°™ì€ ì˜ë¯¸ë¥¼ ê°–ëŠ” ë¬¸ì¥ ê²€ìƒ‰\n",
    "- ëª¨ë¸ í¬ê¸° 22M\n",
    "all-MiniLM-L6-v2\n",
    "- ê¸´ ë¬¸ì„œì—ì„œ ìœ ì‚¬í•œ ë¬¸ì¥ ì°¾ê¸°\n",
    "- ëª¨ë¸ í¬ê¸° 22M\n",
    "paraphrase-mpnet-base-v2\n",
    "- paraphrase-MiniLM-L6-v2ì™€ ê°™ì€ taskë¥¼ í•˜ëŠ” ê³ ê¸‰ ëª¨ë¸\n",
    "- cpuì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê´€ë ¨ ë¬¸ì¥: ìƒˆëŠ” ë‚  ìˆ˜ ìˆëŠ” ë™ë¬¼ì´ë‹¤. (ìœ ì‚¬ë„: 0.8640)\n",
      "ê´€ë ¨ ë¬¸ì¥: ê³ ì–‘ì´ëŠ” ë‹¤ë¦¬ê°€ ë„¤ ê°œì´ë‹¤. (ìœ ì‚¬ë„: 0.8375)\n",
      "ê´€ë ¨ ë¬¸ì¥: ëŒ€ë¶€ë¶„ ì‚¬ëŒë“¤ì€ ê³ ì–‘ì´ê°€ ë‚  ìˆ˜ ì—†ë‹¤ê³  ì£¼ì¥í•œë‹¤. (ìœ ì‚¬ë„: 0.7818)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "# ğŸ”¹ 1. ëª¨ë¸ ë¡œë“œ\n",
    "#model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\", device=\"cpu\")\n",
    "model = SentenceTransformer(\"paraphrase-mpnet-base-v2\", device=\"cpu\")\n",
    "\n",
    "# ğŸ”¹ 2. ì§ˆë¬¸ ë° ë‹µë³€ í›„ë³´\n",
    "query = \"ê³ ì–‘ì´ëŠ” ë‚  ìˆ˜ ìˆë‹¤.\"\n",
    "documents = [\n",
    "    \"ìƒˆëŠ” ë‚  ìˆ˜ ìˆëŠ” ë™ë¬¼ì´ë‹¤.\",\n",
    "    \"ê³ ì–‘ì´ëŠ” ë‹¤ë¦¬ê°€ ë„¤ ê°œì´ë‹¤.\",\n",
    "    \"ëŒ€ë¶€ë¶„ ì‚¬ëŒë“¤ì€ ê³ ì–‘ì´ê°€ ë‚  ìˆ˜ ì—†ë‹¤ê³  ì£¼ì¥í•œë‹¤.\"\n",
    "]\n",
    "\n",
    "# ğŸ”¹ 3. ì„ë² ë”© ìƒì„±\n",
    "query_embedding = model.encode(query)\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "# ğŸ”¹ 4. ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)\n",
    "similarities = util.cos_sim(query_embedding, doc_embeddings)[0]  # (1, N) -> (N,)\n",
    "\n",
    "# ğŸ”¹ 5. ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬\n",
    "top_k = 3\n",
    "top_results = sorted(zip(documents, similarities), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "# ğŸ”¹ 6. ê²°ê³¼ ì¶œë ¥\n",
    "for doc, score in top_results:\n",
    "    print(f\"ê´€ë ¨ ë¬¸ì¥: {doc} (ìœ ì‚¬ë„: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snunlp/KR-SBERT-V40K-klueNLI-augSTS\n",
    "- Sentence-Bertë¥¼ í•œêµ­ì–´ë¡œ fine-tuningí•œ ëª¨ë¸\n",
    "- í•œêµ­ì–´ ê¸°ì¤€ ë‹¤ë¥¸ ëª¨ë¸ì— ë¹„í•´ ì„±ëŠ¥ ì¢‹ìŒ\n",
    "- ëª¨ë¸ í¬ê¸° 420m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸: ì¥ì œì› ì˜ì›ì€ íƒ€ì‚´ë‹¹í–ˆë‚˜ìš”?\n",
      "ìƒìœ„ ë‹µë³€:\n",
      "- ë¬¸ì¥: \n",
      "ì¥ì œì› ì „ êµ­ë¯¼ì˜í˜ ì˜ì›ì´ ìˆ¨ì§„ ì±„ ë°œê²¬ëë‹¤.\n",
      "  ìœ ì‚¬ë„: tensor(0.5864)\n",
      "- ë¬¸ì¥: \n",
      "í˜„ì¬ê¹Œì§€ íƒ€ì‚´ ì •í™©ì€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œìœ¼ë©°, ê²½ì°°ì€ ì •í™•í•œ ì‚¬ë§ ê²½ìœ„ë¥¼ ì¡°ì‚¬ ì¤‘ì´ë‹¤.\n",
      "  ìœ ì‚¬ë„: tensor(0.5236)\n",
      "- ë¬¸ì¥: \n",
      "í˜„ì¥ì—ëŠ” ì¥ ì „ ì˜ì›ì´ ì‘ì„±í•œ ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ìœ ì„œê°€ ë°œê²¬ëœ ê²ƒìœ¼ë¡œ ì „í•´ì¡Œë‹¤.\n",
      "  ìœ ì‚¬ë„: tensor(0.3695)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ (CPU ì‹¤í–‰)\n",
    "#model = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\", device=\"cpu\")\n",
    "model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\", device=\"cpu\")\n",
    "\n",
    "def find_top_k_answers_with_scores(text, query, k=3):\n",
    "    \"\"\"ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê¸´ ê¸€ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ìƒìœ„ kê°œ ë‹µë³€ê³¼ ìœ ì‚¬ë„ë¥¼ í•¨ê»˜ ì°¾ëŠ” í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    # ë¬¸ì¥ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬)\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', text)\n",
    "\n",
    "    # ë¬¸ì¥ ì„ë² ë”© ìƒì„±\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "    # ì§ˆë¬¸ ì„ë² ë”© ìƒì„±\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    # ì§ˆë¬¸ê³¼ ê° ë¬¸ì¥ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    similarities = util.cos_sim(query_embedding, sentence_embeddings)[0]\n",
    "\n",
    "    # ë¬¸ì¥ê³¼ ìœ ì‚¬ë„ë¥¼ í•¨ê»˜ ì €ì¥\n",
    "    sentence_scores = list(zip(sentences, similarities))\n",
    "\n",
    "    # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "    sentence_scores = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # ìƒìœ„ kê°œ ë¬¸ì¥ê³¼ ìœ ì‚¬ë„ ë°˜í™˜\n",
    "    top_k_sentences_with_scores = sentence_scores[:k]\n",
    "\n",
    "    return top_k_sentences_with_scores\n",
    "\n",
    "# ì˜ˆì‹œ ê¸´ ê¸€\n",
    "long_text = \"\"\"\n",
    "ì¥ì œì› ì „ êµ­ë¯¼ì˜í˜ ì˜ì›ì´ ìˆ¨ì§„ ì±„ ë°œê²¬ëë‹¤.\n",
    "\n",
    "1ì¼ ê²½ì°° ë“±ì— ë”°ë¥´ë©´ ì¥ ì „ ì˜ì›ì€ ì „ë‚  ì˜¤í›„ 11ì‹œ 40ë¶„ê²½ ì„œìš¸ ê°•ë™êµ¬ì˜ í•œ ì˜¤í”¼ìŠ¤í…”ì—ì„œ ìˆ¨ì§„ ì±„ ë°œê²¬ëë‹¤.\n",
    "\n",
    "í˜„ì¥ì—ëŠ” ì¥ ì „ ì˜ì›ì´ ì‘ì„±í•œ ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ìœ ì„œê°€ ë°œê²¬ëœ ê²ƒìœ¼ë¡œ ì „í•´ì¡Œë‹¤. ìœ ì„œì—ëŠ” â€œê°€ì¡±ë“¤ì—ê²Œ ë¯¸ì•ˆí•˜ë‹¤â€ â€œì‚¬ë‘í•œë‹¤â€ ë“± ê°€ì¡±ì„ í–¥í•œ ë‚´ìš©ì´ ë‹´ê²¼ë˜ ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œë‹¤.\n",
    "\n",
    "í˜„ì¬ê¹Œì§€ íƒ€ì‚´ ì •í™©ì€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œìœ¼ë©°, ê²½ì°°ì€ ì •í™•í•œ ì‚¬ë§ ê²½ìœ„ë¥¼ ì¡°ì‚¬ ì¤‘ì´ë‹¤.\n",
    "\n",
    "ì¥ ì „ ì˜ì›ì€ 2015ë…„ 11ì›” ë¶€ì‚°ì˜ í•œ ëŒ€í•™ ë¶€ì´ì¥ìœ¼ë¡œ ì¬ì§í•  ë‹¹ì‹œ ë¹„ì„œë¥¼ ì„±í­í–‰í•œ í˜ì˜ë¡œ ê³ ì†Œëë‹¤.\n",
    "\n",
    "ê³ ì†Œì¸ì€ ê²½ì°° ì¡°ì‚¬ì—ì„œ â€œì¥ ì „ ì˜ì›ì˜ ì´ì„  ì¶œë§ˆë¥¼ ì•ë‘ê³  ì„ ê±° í¬ìŠ¤í„°ë¥¼ ì´¬ì˜í•œ ë’¤ ë’¤í’€ì´ ìë¦¬ì—ì„œ ìˆ ì„ ë§ˆì…¨ë‹¤. ì´í›„ ìì‹ ì—ê²Œ ì„±í­ë ¥ì„ ì €ì§ˆë €ë‹¤â€ê³  ì§„ìˆ í•œ ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œë‹¤. ë˜ ì‚¬ê±´ í”¼í•´ ì§í›„ ì¥ ì „ ì˜ì›ìœ¼ë¡œë¶€í„° â€˜ê·¸ë ‡ê²Œ ê°€ë©´ ë‚´ ë§ˆìŒì€ ì–´ë–¡í•´â€™ë¼ëŠ” ë‚´ìš©ì˜ ë¬¸ìë©”ì‹œì§€ë¥¼ ë°›ì•˜ìœ¼ë©°, ì´ë¥¼ ë³´ê´€í•˜ê³  ìˆë‹¤ê°€ ê²½ì°°ì— ì œì¶œí•œ ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œë‹¤.\n",
    "\n",
    "ê²½ì°°ì€ ì§€ë‚œë‹¬ 28ì¼ ì¤€ê°•ê°„ì¹˜ìƒ í˜ì˜ë¡œ ê³ ì†Œë‹¹í•œ ì¥ ì „ ì˜ì›ì„ ì†Œí™˜í–ˆë‹¤. ì¥ ì „ ì˜ì›ì€ ê²½ì°° ì¡°ì‚¬ì—ì„œ í˜ì˜ë¥¼ ì „ë©´ ë¶€ì¸í•œ ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œë‹¤.\n",
    "\n",
    "ì¥ ì „ ì˜ì› ì¸¡ì€ 2ì¼ë¶€í„° ë¶€ì‚°í•´ìš´ëŒ€ë°±ë³‘ì›ì— ë¹ˆì†Œë¥¼ ë§ˆë ¨í•˜ê³  ì¡°ë¬¸ì„ ë°›ê¸°ë¡œ í–ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "query = \"ì¥ì œì› ì˜ì›ì€ íƒ€ì‚´ë‹¹í–ˆë‚˜ìš”?\"\n",
    "\n",
    "# ìƒìœ„ 2ê°œ ë‹µë³€ê³¼ ìœ ì‚¬ë„ ì°¾ê¸°\n",
    "top_answers_with_scores = find_top_k_answers_with_scores(long_text, query, k=3)\n",
    "\n",
    "print(\"ì§ˆë¬¸:\", query)\n",
    "print(\"ìƒìœ„ ë‹µë³€:\")\n",
    "for sentence, score in top_answers_with_scores:\n",
    "    print(\"- ë¬¸ì¥:\", sentence)\n",
    "    print(\"  ìœ ì‚¬ë„:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¨ìˆœí•˜ê²Œ ë‹¨ì–´ ê²¹ì¹˜ëŠ” ì •ë„ë¡œ ë¹„êµí•œ ìœ ì‚¬ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìì¹´ë“œ ìœ ì‚¬ë„ ìˆœìœ„:\n",
      "- ë¬¸ì¥: ìƒˆëŠ” ë‚  ìˆ˜ ìˆëŠ” ë™ë¬¼ì´ë‹¤.\n",
      "  ìœ ì‚¬ë„: 0.2857142857142857\n",
      "- ë¬¸ì¥: ëŒ€ë¶€ë¶„ ì‚¬ëŒë“¤ì€ ê³ ì–‘ì´ê°€ ë‚  ìˆ˜ ì—†ë‹¤ê³  ì£¼ì¥í•œë‹¤.\n",
      "  ìœ ì‚¬ë„: 0.2222222222222222\n",
      "- ë¬¸ì¥: ê³ ì–‘ì´ëŠ” ë‹¤ë¦¬ê°€ ë„¤ ê°œì´ë‹¤.\n",
      "  ìœ ì‚¬ë„: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def jaccard_similarity(sentence1, sentence2):\n",
    "    \n",
    "    set1 = set(sentence1.split())\n",
    "    set2 = set(sentence2.split())\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union else 0\n",
    "\n",
    "query = \"ê³ ì–‘ì´ëŠ” ë‚  ìˆ˜ ìˆë‹¤.\"\n",
    "documents = [\n",
    "    \"ìƒˆëŠ” ë‚  ìˆ˜ ìˆëŠ” ë™ë¬¼ì´ë‹¤.\",\n",
    "    \"ê³ ì–‘ì´ëŠ” ë‹¤ë¦¬ê°€ ë„¤ ê°œì´ë‹¤.\",\n",
    "    \"ëŒ€ë¶€ë¶„ ì‚¬ëŒë“¤ì€ ê³ ì–‘ì´ê°€ ë‚  ìˆ˜ ì—†ë‹¤ê³  ì£¼ì¥í•œë‹¤.\"\n",
    "]\n",
    "\n",
    "similarities = []\n",
    "for doc in documents:\n",
    "    similarity = jaccard_similarity(query, doc)\n",
    "    similarities.append((doc, similarity))\n",
    "\n",
    "# ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"ìì¹´ë“œ ìœ ì‚¬ë„ ìˆœìœ„:\")\n",
    "for doc, similarity in similarities:\n",
    "    print(f\"- ë¬¸ì¥: {doc}\")\n",
    "    print(f\"  ìœ ì‚¬ë„: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snunlp/KR-SBERT-V40K-klueNLI-augSTS ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì¥ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê´€ë ¨ ë¬¸ì¥: \n",
      "ë°°ìš° ê¹€ìˆ˜í˜„ì´ ì§€ë‚œë‹¬ 16ì¼ ì„¸ìƒì„ ë– ë‚œ ê³ (æ•…) ê¹€ìƒˆë¡  ë°°ìš°ê°€ ì„±ì¸ì´ ëœ í›„ 1ë…„ ê°„ êµì œë¥¼ í–ˆë‹¤ê³  ë°í˜”ë‹¤. (ìœ ì‚¬ë„: 0.6663)\n",
      "ê´€ë ¨ ë¬¸ì¥: \n",
      "ì´í›„ ê¹€ìˆ˜í˜„ ì¸¡ì€ ê¹€ìƒˆë¡ ì´ ì„±ì¸ì´ë˜ 2019ë…„ ì—¬ë¦„ë¶€í„° 2020ë…„ ê°€ì„ê¹Œì§€ êµì œí–ˆë‹¤ê³  ë°˜ë°•ì— ë‚˜ì„°ë‹¤. (ìœ ì‚¬ë„: 0.6038)\n",
      "ê´€ë ¨ ë¬¸ì¥: \n",
      "ê·¸ëŠ” ê¹€ìƒˆë¡ ê³¼ì˜ êµì œ ì‚¬ì‹¤ì€ ì¸ì •í•˜ë©´ì„œë„, ë¯¸ì„±ë…„ì ì‹œì ˆë¶€í„° ë§Œë‚¨ì„ ê°€ì¡Œë‹¤ëŠ” ì˜í˜¹ì— ëŒ€í•´ì„œëŠ” ê°•í•˜ê²Œ ë¶€ì¸í–ˆë‹¤. (ìœ ì‚¬ë„: 0.5509)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ (CPU ì‹¤í–‰)\n",
    "model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\", device=\"cpu\")\n",
    "\n",
    "def find_top_k_answers_regex(text, query, k=3):\n",
    "    \"\"\"ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê¸´ ê¸€ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ìƒìœ„ kê°œ ë‹µë³€ì„ ì°¾ëŠ” í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    # ë¬¸ì¥ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬)\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', text)\n",
    "\n",
    "    # ë¬¸ì¥ ì„ë² ë”© ìƒì„±\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "    # ì§ˆë¬¸ ì„ë² ë”© ìƒì„±\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    # ì§ˆë¬¸ê³¼ ê° ë¬¸ì¥ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    similarities = util.cos_sim(query_embedding, sentence_embeddings)[0]\n",
    "\n",
    "    # ìœ ì‚¬ë„ì™€ ë¬¸ì¥ ì¸ë±ìŠ¤ë¥¼ í•¨ê»˜ ì €ì¥\n",
    "    sentence_scores = list(zip(sentences, similarities))\n",
    "\n",
    "    # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "    sentence_scores = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # ìƒìœ„ kê°œ ë¬¸ì¥ ë°˜í™˜\n",
    "    top_k_sentences_with_scores = sentence_scores[:k]\n",
    "\n",
    "    return top_k_sentences_with_scores\n",
    "\n",
    "# ì˜ˆì‹œ ê¸´ ê¸€\n",
    "long_text = \"\"\"\n",
    "ë°°ìš° ê¹€ìˆ˜í˜„ì´ ì§€ë‚œë‹¬ 16ì¼ ì„¸ìƒì„ ë– ë‚œ ê³ (æ•…) ê¹€ìƒˆë¡  ë°°ìš°ê°€ ì„±ì¸ì´ ëœ í›„ 1ë…„ ê°„ êµì œë¥¼ í–ˆë‹¤ê³  ë°í˜”ë‹¤. ë…¼ë€ì´ ë¶ˆê±°ì§„ ì§€ ì•½ 3ì£¼ ë§Œì— ì²˜ìŒìœ¼ë¡œ ê³µê°œ ì„ìƒì— ëª¨ìŠµì„ ë“œëŸ¬ë‚¸ ê·¸ëŠ”, ë¯¸ì„±ë…„ì êµì œ ì˜í˜¹ì„ ë¶€ì¸í•˜ë©° ì–µìš¸í•¨ì„ í˜¸ì†Œí–ˆë‹¤.\n",
    "\n",
    "ê¹€ìˆ˜í˜„ì˜ ì†Œì†ì‚¬ ê³¨ë“œë©”ë‹¬ë¦¬ìŠ¤íŠ¸ëŠ” 31ì¼ ì˜¤í›„ 4ì‹œ 30ë¶„ ì„œìš¸ ë§ˆí¬êµ¬ ìƒì•”ë™ ìŠ¤íƒ í¬ë“œí˜¸í…”ì—ì„œ ê¸´ê¸‰ ê¸°ìíšŒê²¬ì„ ì—´ì—ˆë‹¤.\n",
    "\n",
    "ê¹€ìˆ˜í˜„ì€ â€œë¨¼ì € ì£„ì†¡í•˜ë‹¤. ì € í•œ ì‚¬ëŒ ë•Œë¬¸ì— ë„ˆë¬´ ë§ì€ ë¶„ë“¤ì´ ê³ í†µë°›ê³  ìˆëŠ” ê²ƒ ê°™ë‹¤. ê·¸ë¦¬ê³  ê³ ì¸ë„ í¸íˆ ì ë“¤ì§€ ëª»í•˜ê³  ìˆëŠ” ê²ƒ ê°™ì•„ì„œ ì•ˆíƒ€ê¹Œìš´ ë§ˆìŒë¿ì´ë‹¤â€ë¼ë©° ì…ì„ ì—´ì—ˆë‹¤.\n",
    "\n",
    "ì´ì–´ ê¹€ìˆ˜í˜„ì€ â€œì²˜ìŒë¶€í„° ì´ ìë¦¬ì—ì„œ ëª¨ë“  ê±¸ ë‹¤ ì´ì•¼ê¸°í•˜ë©´ ì–´ë• ì„ê¹Œ í•˜ëŠ” ìƒê°ì„ í–ˆë‹¤. ê·¸ë¬ìœ¼ë©´ ì €ë¥¼ ì‚¬ë‘í•´ì£¼ì‹  íŒ¬ë¶„ë“¤, ì´ ê¸°ìíšŒê²¬ê¹Œì§€ ë§í•  ìˆ˜ ì—†ì´ ì• ì¨ì£¼ì‹  íšŒì‚¬ ì‹êµ¬ë¶„ë“¤, ë‹¤ ì´í† ë¡ ê´´ë¡­ì§€ëŠ” ì•Šì§€ ì•Šì•˜ì„ê¹Œâ€ë¼ë©° â€œì €ì™€ ê³ ì¸ì˜ ì‚¬ìƒí™œì´ í­ë¡œë  ë•Œë§ˆë‹¤ ë‚´ì¼ì€ ê·¸ëƒ¥ ë‹¤ ì´ì•¼ê¸°í•˜ì, ì§ì ‘ ë§í•˜ê³  ì´ ì§€ì˜¥ ê°™ì€ ìƒí™©ì„ ëë‚´ìëŠ” ìƒê°ì„ ê³„ì† í–ˆì—ˆë‹¤â€ë¼ê³  ì´ì•¼ê¸°í–ˆë‹¤.\n",
    "\n",
    "ê·¸ëŠ” ê¹€ìƒˆë¡ ê³¼ì˜ êµì œ ì‚¬ì‹¤ì€ ì¸ì •í•˜ë©´ì„œë„, ë¯¸ì„±ë…„ì ì‹œì ˆë¶€í„° ë§Œë‚¨ì„ ê°€ì¡Œë‹¤ëŠ” ì˜í˜¹ì— ëŒ€í•´ì„œëŠ” ê°•í•˜ê²Œ ë¶€ì¸í–ˆë‹¤. ê·¸ëŠ” â€œì €ì™€ ê³ ì¸ì€ 5ë…„ ì „, ë“œë¼ë§ˆ ëˆˆë¬¼ì˜ ì—¬ì™•ì´ ë°©ì˜ë˜ê¸° 4ë…„ ì „ì— ì•½ 1ë…„ê°„ êµì œí–ˆë‹¤â€ë©° â€œê³ ì¸ì´ ë¯¸ì„±ë…„ìì´ë˜ ì‹œì ˆ êµì œë¥¼ í•˜ì§€ ì•Šì•˜ë‹¤â€ê³  ê°•ë ¥íˆ ì£¼ì¥í–ˆë‹¤.\n",
    "\n",
    "ë˜í•œ, ê³ ì¸ì˜ ì‚¬ë§ ì›ì¸ì´ ì†Œì†ì‚¬ì˜ ì••ë°• ë•Œë¬¸ì´ë¼ëŠ” ì£¼ì¥ì—ë„ ë°˜ë°•í–ˆë‹¤. ê·¸ëŠ” â€œê³ ì¸ì´ ì €ì˜ ì™¸ë©´ìœ¼ë¡œ ì¸í•´, ì €í¬ ì†Œì†ì‚¬ê°€ ê³ ì¸ì˜ ì±„ë¬´ë¥¼ ì••ë°•í–ˆê¸° ë•Œë¬¸ì— ë¹„ê·¹ì ì¸ ì„ íƒì„ í–ˆë‹¤ëŠ” ê²ƒ ë˜í•œ ì‚¬ì‹¤ì´ ì•„ë‹ˆë‹¤â€ë©° â€œí‰ë²”í•œ ì—°ì¸ì´ì—ˆê³ , ì„œë¡œ ì¢‹ì€ ê°ì •ì„ ê°–ê³  ë§Œë‚¬ìœ¼ë‚˜ ì‹œê°„ì´ ì§€ë‚˜ í—¤ì–´ì¡Œì„ ë¿â€ì´ë¼ê³  ë§í–ˆë‹¤.\n",
    "\n",
    "ê¹€ìˆ˜í˜„ì€ â€œì €í¬ ì†Œì†ì‚¬ê°€ ê³ ì¸ê³¼ì˜ ì±„ë¬´ ê´€ê³„ì— ëŒ€í•´ 2ì°¨ ë‚´ìš©ì¦ëª…ì„ ë³´ë‚´ ê³ ì¸ì—ê²Œ ì±„ë¬´ì— ëŒ€í•´ ì••ë°•ëœ ê²ƒì²˜ëŸ¼ ë§í–ˆë‹¤. í•˜ì§€ë§Œ 1ë…„ ì „ ì œ ì†Œì†ì‚¬ ëŒ€í‘œì™€ì˜ í†µí™”ì—ì„œëŠ” ì „í˜€ ë‹¤ë¥¸ ë§ì„ í•˜ê³  ìˆì—ˆë‹¤â€ë¼ë©° ê³ ì¸ì˜ ìœ ì¡±ê³¼ ì†Œì†ì‚¬ ëŒ€í‘œì™€ì˜ í†µí™” ë…¹ìŒë³¸ì„ ê³µê°œí–ˆë‹¤.\n",
    "\n",
    "ì´ì–´ ê¹€ìˆ˜í˜„ì€ â€œê³ ì¸ì˜ ë§ˆì§€ë§‰ ì†Œì†ì‚¬ ëŒ€í‘œê°€ 1ë…„ ì „ í†µí™”ì™€ ì™„ì „íˆ ë‹¤ë¥¸ ê±°ì§“ë§ì„ í•˜ê³  ìˆë‹¤. ì œê°€ ì˜ëª»í•œ ì¼ì€ ì–¼ë§ˆë“ ì§€ ì¸ì •í•˜ê² ë‹¤. ì±…ì„ì ¸ì•¼ í•  ì¼ì´ ìˆë‹¤ë©´ ì±…ì„ì§€ëŠ”ê²Œ ë‹¹ì—°í•˜ë‹¤ê³  ìƒê°í•œë‹¤â€ë¼ê³  ë§í–ˆë‹¤.\n",
    "\n",
    "ê¹€ìˆ˜í˜„ì€ ê³ ì¸ê³¼ì˜ ê´€ê³„ê°€ ê³µê°œëœ ì´í›„, í˜‘ë°•ê³¼ ê±°ì§“ëœ ì¦ê±°ë“¤ì´ ê³„ì† ë“±ì¥í–ˆë‹¤ê³  ì£¼ì¥í–ˆë‹¤. ê·¸ëŠ” â€œë‚ ë§ˆë‹¤ ìƒˆë¡œìš´ í­ë¡œê°€ ì˜ˆê³ ë˜ê³ , ê±°ì§“ì„ ì‚¬ì‹¤ì²˜ëŸ¼ ì¸ì •í•˜ë¼ëŠ” ê°•ìš”ë¥¼ ë°›ì•˜ì§€ë§Œ í•˜ì§€ ì•Šì€ ì¼ì„ í–ˆë‹¤ê³  ë§í•  ìˆ˜ëŠ” ì—†ë‹¤â€ê³  ë‹¨í˜¸í•œ ì…ì¥ì„ ë°í˜”ë‹¤.\n",
    "\n",
    "íŠ¹íˆ, ê³ ì¸ì˜ ìœ ì¡± ì¸¡ì´ ì œì‹œí•œ ì¦ê±°ì— ëŒ€í•´ ì˜ë¬¸ì„ ì œê¸°í•˜ë©° ì´ë¥¼ ê²€ì¦í•  ê²ƒì„ ìš”ì²­í–ˆë‹¤. ê¹€ìˆ˜í˜„ì€ â€œìœ ì¡±ì´ ê³µê°œí•œ 2016ë…„ê³¼ 2018ë…„ ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” ì† ì¸ë¬¼ì€ ì„œë¡œ ë‹¤ë¥¸ ì‚¬ëŒì´ë¼ëŠ” ë¶„ì„ ê²°ê³¼ë¥¼ ê²€ì¦ ê¸°ê´€ì„ í†µí•´ í™•ì¸í–ˆë‹¤â€ë©° â€œ2016ë…„ì— ì´¬ì˜ëë‹¤ê³  ë°íŒ ì‚¬ì§„ì€ 2019ë…„ì— ì´¬ì˜ëœ ì‚¬ì§„ì´ë©°, 4ë…„ê°„ ëª¸ ë‹´ì•˜ë˜ ì†Œì†ì‚¬ ì´ë¦„ê³¼ ê³„ì•½ê¸°ê°„ ì—­ì‹œ í‹€ë ¸ë‹¤â€ê³  ë°í˜”ë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬ë©´ì„œ â€œìœ ì¡± ì¸¡ì´ ê°€ì§„ ì¦ê±°ê°€ ì •ë§ ì§„ì‹¤ì´ë¼ë©´, ìˆ˜ì‚¬ê¸°ê´€ì— ëª¨ë“  ìë£Œë¥¼ ì œì¶œí•˜ê³  ë²•ì ì¸ ì ˆì°¨ë¥¼ í†µí•´ ê²€ì¦ë°›ì„ ê²ƒì„ ìš”ì²­í•œë‹¤â€ë¼ê³  ìš”êµ¬í–ˆë‹¤.\n",
    "\n",
    "ëìœ¼ë¡œ ê·¸ëŠ” â€œì œê°€ í•œ ì¼ì€ ì–´ë–¤ ë¹„ë‚œë„ ê°ìˆ˜í•˜ê² ë‹¤â€ë©´ì„œë„ â€œí•˜ì§€ë§Œ, í•˜ì§€ ì•Šì€ ê²ƒì€ í•˜ì§€ ì•Šì€ ê²ƒì´ë‹¤. ì €ë¥¼ ë¯¿ì–´ì£¼ì‹œëŠ” ëª¨ë“  ë¶„ë“¤ì„ ìœ„í•´ì„œ ê·¸ê²ƒë§Œí¼ì€ ë°íˆê³  ì‹¶ë‹¤â€ë©° ê²°ë°±ì„ ì£¼ì¥í–ˆë‹¤.\n",
    "\n",
    "ì´ë‚  ê¸°ìíšŒê²¬ì—ëŠ” ê¹€ìˆ˜í˜„ê³¼ ì†Œì†ì‚¬ ê³¨ë“œë©”ë‹¬ë¦¬ìŠ¤íŠ¸ì˜ ë²•ë¥ ëŒ€ë¦¬ì¸ì¸ ê¹€ì¢…ë³µ ë³€í˜¸ì‚¬ë„ ë™í–‰í•´ ê³µì‹ ì…ì¥ì„ ë°í˜”ë‹¤. ê¹€ ë³€í˜¸ì‚¬ëŠ” â€œê¹€ìˆ˜í˜„ ë°°ìš°ê°€ ì§ì ‘ ì…ì¥ì„ í‘œëª…í•œ ë§Œí¼, ì‚¬ì‹¤ê´€ê³„ë¥¼ ëª…í™•íˆ ë°íˆê³ ì ê´€ë ¨ìë“¤ì— ëŒ€í•œ í˜•ì‚¬ ê³ ì†Œ ë° ë¯¼ì‚¬ ì†Œì†¡ì„ ì œê¸°í•˜ê¸°ë¡œ í–ˆë‹¤â€ê³  ì „í–ˆë‹¤.\n",
    "\n",
    "ì´ì–´ â€œì˜¤ëŠ˜ ìœ ì¡±ê³¼ ì´ëª¨ë¼ê³  ì£¼ì¥í•˜ëŠ” ì„¤ëª…ë¶ˆìƒì, ê·¸ë¦¬ê³  ê°€ë¡œì„¸ë¡œì—°êµ¬ì†Œ(ê°€ì„¸ì—°) ìš´ì˜ìë¥¼ ìƒëŒ€ë¡œ ì •ë³´í†µì‹ ë§ë²• ìœ„ë°˜(ëª…ì˜ˆí›¼ì†) í˜ì˜ë¡œ ê³ ì†Œì¥ì„ ì œì¶œí•  ì˜ˆì •ì´ë©°, 120ì–µ ì› ìƒë‹¹ì˜ ì†í•´ë°°ìƒ ì²­êµ¬ ì†Œì†¡ë„ ì„œìš¸ì¤‘ì•™ì§€ë°©ë²•ì›ì— ì œì¶œí•  ê³„íšâ€ì´ë¼ê³  ë°í˜”ë‹¤.\n",
    "\n",
    "ë˜í•œ â€œí˜„ì¬ ì´ ì‚¬ì•ˆì€ ìˆ˜ì‚¬ ëŒ€ìƒì´ê¸° ë•Œë¬¸ì— ì¶”ê°€ì ì¸ ì§ˆì˜ì‘ë‹µì„ ë°›ì§€ ì•ŠëŠ”ë‹¤â€ë©° â€œì´ ì ì„ ì–‘í•´í•´ë‹¬ë¼â€ê³  ë§ë¶™ì˜€ë‹¤.\n",
    "\n",
    "ê¸°ìíšŒê²¬ì„ ë§ˆì¹œ í›„ ê¹€ìˆ˜í˜„ì´ íšŒê²¬ì¥ì„ ë– ë‚˜ë ¤ í•˜ì, í•œ ì·¨ì¬ì§„ì´ â€œê¹€ìƒˆë¡ ì„ ì–¸ì œ ì–´ë””ì„œ ì²˜ìŒ ë§Œë‚¬ëŠ”ì§€ ë§í•´ ë‹¬ë¼. ì´ ì •ë„ëŠ” ë§í•´ ì¤„ ìˆ˜ ìˆì§€ ì•ŠëŠëƒâ€ê³  ì§ˆë¬¸í–ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¹€ìˆ˜í˜„ì€ ë³„ë‹¤ë¥¸ ë‹µë³€ì„ í•˜ì§€ ì•Šì€ ì±„ ìë¦¬ë¥¼ ë– ë‚¬ë‹¤.\n",
    "\n",
    "í•œí¸, ê¹€ìƒˆë¡ ì€ ì§€ë‚œë‹¬ 16ì¼ ì˜¤í›„ 4ì‹œ 54ë¶„ê²½ ì„œìš¸ ì„±ë™êµ¬ ì†Œì¬ ìíƒì—ì„œ ìˆ¨ì§„ ì±„ ë°œê²¬ëë‹¤. ìœ ì¡± ì¸¡ì€ ì§€ë‚œ 10ì¼ ìœ íŠœë¸Œ ì±„ë„ â€˜ê°€ë¡œì„¸ë¡œ ì—°êµ¬ì†Œâ€™(ê°€ì„¸ì—°)ë¥¼ í†µí•´ ê¹€ìƒˆë¡ ì´ ë§Œ 15ì„¸ì˜€ë˜ 2015ë…„ 11ì›” 19ì¼ë¶€í„° 2021ë…„ 7ì›” 7ì¼ê¹Œì§€ ì•½ 6ë…„ê°„ ê¹€ìˆ˜í˜„ê³¼ êµì œí–ˆë‹¤ê³  ì£¼ì¥í–ˆë‹¤.\n",
    "\n",
    "ì´í›„ ê¹€ìˆ˜í˜„ ì¸¡ì€ ê¹€ìƒˆë¡ ì´ ì„±ì¸ì´ë˜ 2019ë…„ ì—¬ë¦„ë¶€í„° 2020ë…„ ê°€ì„ê¹Œì§€ êµì œí–ˆë‹¤ê³  ë°˜ë°•ì— ë‚˜ì„°ë‹¤. ì´ì— ê¹€ìƒˆë¡  ìœ ì¡± ì¸¡ì€ 27ì¼ ë²•ë¥ ëŒ€ë¦¬ì¸ ë¶€ì§€ì„ ë²•ë¬´ë²•ì¸ ë¶€ìœ  ëŒ€í‘œë³€í˜¸ì‚¬ì™€ ê¸°ìíšŒê²¬ì„ ì—´ì–´ ê¹€ìƒˆë¡ ì´ ë§Œ 16ì„¸ ì‹œì ˆ ê¹€ìˆ˜í˜„ê³¼ ë‚˜ëˆˆ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ì™€ í¸ì§€ ë‚´ìš©ì„ ê³µê°œí–ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "query = \"ê·¸ë˜ì„œ ê¹€ìˆ˜í˜„ì´ë‘ ê¹€ìƒˆë¡ ì´ë‘ ë¯¸ì„±ë…„ìì¼ ë•Œ ì‚¬ê·„ê±°ì§€?\"\n",
    "\n",
    "# ìƒìœ„ 3ê°œ ë‹µë³€ê³¼ ìœ ì‚¬ë„ ì°¾ê¸°\n",
    "top_answers_with_scores = find_top_k_answers_regex(long_text, query, k=3)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for sentence, score in top_answers_with_scores:\n",
    "    print(f\"ê´€ë ¨ ë¬¸ì¥: {sentence} (ìœ ì‚¬ë„: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLI task í…ŒìŠ¤íŠ¸\n",
    "- ê¸°ì¤€ ë¬¸ì¥ í•˜ë‚˜ì™€ ë¹„êµí•  ë¬¸ì¥ ì—¬ëŸ¬ê°œê°€ ìˆì„ ë•Œ ê° ë¹„êµ ë¬¸ì¥ì´ ê¸°ì¤€ ë¬¸ì¥ì— ëŒ€í•´ì„œ ì°¬(entailment), ë°˜(contradiction), ì¤‘ë¦½(neutral)ìœ¼ë¡œ íŒë‹¨\n",
    "- ì•„ë˜ ëª¨ë¸ë“¤ì— ëŒ€í•´ì„œ í…ŒìŠ¤íŠ¸ë¥¼ í•˜ì˜€ìœ¼ë‚˜ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ë‹¤ë¥¸ ê²°ê³¼ê°€ ë‚˜ì˜¤ê³  ê²°ê³¼ê°€ ì •í™•í•˜ì§€ ì•ŠìŒ\n",
    "- ì˜ì–´ ëª¨ë¸ë¡œ ì‹¤í–‰í•œ ë’¤ ë²ˆì—­í•˜ëŠ” ë°©ì‹ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¦ê±° ë¬¸ì¥: ì¹´í˜ì¸ì€ ì¤‘ì¶” ì‹ ê²½ê³„ë¥¼ ìê·¹í•˜ì—¬ ì¡¸ìŒì„ ì¤„ì¸ë‹¤. â†’ ê²°ê³¼: contradiction (ì‹ ë¢°ë„: 0.3346)\n",
      "ì¦ê±° ë¬¸ì¥: ì»¤í”¼ë¥¼ ë§ˆì‹œë©´ ì˜¤íˆë ¤ í”¼ê³¤í•´ì§ˆ ìˆ˜ë„ ìˆë‹¤. â†’ ê²°ê³¼: contradiction (ì‹ ë¢°ë„: 0.3347)\n",
      "ì¦ê±° ë¬¸ì¥: ì ì„ ê¹¨ìš°ëŠ” íš¨ê³¼ëŠ” ê°œì¸ì°¨ê°€ ìˆë‹¤. â†’ ê²°ê³¼: contradiction (ì‹ ë¢°ë„: 0.3377)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# NLI ëª¨ë¸ ë¡œë“œ\n",
    "#nli_model = pipeline(\"zero-shot-classification\", model=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")  \n",
    "#nli_model = pipeline(\"zero-shot-classification\", model=\"beomi/kcbert-base\")\n",
    "#nli_model = pipeline(\"zero-shot-classification\", model=\"monologg/koelectra-base-v3-discriminator\")\n",
    "#nli_model = pipeline(\"zero-shot-classification\", model=\"klue/bert-base\")\n",
    "#nli_model = pipeline(\"zero-shot-classification\", model=\"klue/roberta-base\")\n",
    "#nli_model = pipeline(\"zero-shot-classification\", model=\"jhgan/ko-sbert-nli\")\n",
    "nli_model = pipeline(\"zero-shot-classification\", model=\"klue/roberta-large\")\n",
    "\n",
    "# ê¸°ë³¸ ë¬¸ì¥(ì°¸/ê±°ì§“ì„ íŒë³„í•˜ê³  ì‹¶ì€ ë¬¸ì¥)\n",
    "claim = \"ì»¤í”¼ëŠ” ì ì„ ê¹¨ìš´ë‹¤.\"\n",
    "\n",
    "# ì¦ê±° ë¬¸ì¥(ì°¸ê³ í•  ë¬¸ì¥ë“¤)\n",
    "evidence_sentences = [\n",
    "    \"ì¹´í˜ì¸ì€ ì¤‘ì¶” ì‹ ê²½ê³„ë¥¼ ìê·¹í•˜ì—¬ ì¡¸ìŒì„ ì¤„ì¸ë‹¤.\",\n",
    "    \"ì»¤í”¼ë¥¼ ë§ˆì‹œë©´ ì˜¤íˆë ¤ í”¼ê³¤í•´ì§ˆ ìˆ˜ë„ ìˆë‹¤.\",\n",
    "    \"ì ì„ ê¹¨ìš°ëŠ” íš¨ê³¼ëŠ” ê°œì¸ì°¨ê°€ ìˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# NLI ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  ë¼ë²¨ (ì°¸: \"entailment\", ê±°ì§“: \"contradiction\", ì¤‘ë¦½: \"neutral\")\n",
    "labels = [\"entailment\", \"contradiction\", \"neutral\"]\n",
    "\n",
    "# ê° ì¦ê±° ë¬¸ì¥ê³¼ ë¹„êµí•˜ì—¬ ì°¸/ê±°ì§“ íŒë³„\n",
    "for evidence in evidence_sentences:\n",
    "    result = nli_model(evidence, candidate_labels=labels)\n",
    "    print(f\"ì¦ê±° ë¬¸ì¥: {evidence} â†’ ê²°ê³¼: {result['labels'][0]} (ì‹ ë¢°ë„: {result['scores'][0]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¦ê±° ë¬¸ì¥: í˜„ì¬ê¹Œì§€ íƒ€ì‚´ ì •í™©ì€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œìœ¼ë©°, ê²½ì°°ì€ ì •í™•í•œ ì‚¬ë§ ê²½ìœ„ë¥¼ ì¡°ì‚¬ ì¤‘ì´ë‹¤.\n",
      "ë ˆë²¨: NEUTRAL (ì‹ ë¢°ë„: 0.3376)\n",
      "ë ˆë²¨: ENTAILMENT (ì‹ ë¢°ë„: 0.3314)\n",
      "ë ˆë²¨: CONTRADICTION (ì‹ ë¢°ë„: 0.3311)\n",
      "ì¦ê±° ë¬¸ì¥: ì¥ì œì› ì „ êµ­ë¯¼ì˜í˜ ì˜ì›ì´ ìˆ¨ì§„ ì±„ ë°œê²¬ëë‹¤.\n",
      "ë ˆë²¨: CONTRADICTION (ì‹ ë¢°ë„: 0.3583)\n",
      "ë ˆë²¨: ENTAILMENT (ì‹ ë¢°ë„: 0.3578)\n",
      "ë ˆë²¨: NEUTRAL (ì‹ ë¢°ë„: 0.2839)\n",
      "ì¦ê±° ë¬¸ì¥: í˜„ì¥ì—ëŠ” ì¥ ì „ ì˜ì›ì´ ì‘ì„±í•œ ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ìœ ì„œê°€ ë°œê²¬ëœ ê²ƒìœ¼ë¡œ ì „í•´ì¡Œë‹¤.\n",
      "ë ˆë²¨: ENTAILMENT (ì‹ ë¢°ë„: 0.3407)\n",
      "ë ˆë²¨: CONTRADICTION (ì‹ ë¢°ë„: 0.3344)\n",
      "ë ˆë²¨: NEUTRAL (ì‹ ë¢°ë„: 0.3249)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# zero-shot classification íŒŒì´í”„ë¼ì¸ ë¡œë“œ\n",
    "nli_model = pipeline(\"zero-shot-classification\", model=\"beomi/kcbert-base\")\n",
    "\n",
    "# ê¸°ë³¸ ë¬¸ì¥(ì°¸/ê±°ì§“ì„ íŒë³„í•˜ê³  ì‹¶ì€ ë¬¸ì¥)\n",
    "claim = \"ì¥ì œì› ì˜ì›ì€ íƒ€ì‚´ë‹¹í•¨\"\n",
    "\n",
    "# ì¦ê±° ë¬¸ì¥(ì°¸ê³ í•  ë¬¸ì¥ë“¤)\n",
    "evidence_sentences = [\n",
    "    \"í˜„ì¬ê¹Œì§€ íƒ€ì‚´ ì •í™©ì€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œìœ¼ë©°, ê²½ì°°ì€ ì •í™•í•œ ì‚¬ë§ ê²½ìœ„ë¥¼ ì¡°ì‚¬ ì¤‘ì´ë‹¤.\",\n",
    "    \"ì¥ì œì› ì „ êµ­ë¯¼ì˜í˜ ì˜ì›ì´ ìˆ¨ì§„ ì±„ ë°œê²¬ëë‹¤.\",\n",
    "    \"í˜„ì¥ì—ëŠ” ì¥ ì „ ì˜ì›ì´ ì‘ì„±í•œ ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ìœ ì„œê°€ ë°œê²¬ëœ ê²ƒìœ¼ë¡œ ì „í•´ì¡Œë‹¤.\"\n",
    "]\n",
    "\n",
    "# zero-shot classificationì„ ìœ„í•œ í›„ë³´ ë ˆì´ë¸”\n",
    "labels = [\"ENTAILMENT\", \"CONTRADICTION\", \"NEUTRAL\"]\n",
    "\n",
    "# ê° ì¦ê±° ë¬¸ì¥ê³¼ ë¹„êµí•˜ì—¬ ì°¸/ê±°ì§“ íŒë³„\n",
    "for evidence in evidence_sentences:\n",
    "    result = nli_model(evidence, candidate_labels=labels, hypothesis=claim)\n",
    "    \n",
    "    print(f\"ì¦ê±° ë¬¸ì¥: {evidence}\")\n",
    "    # ê²°ê³¼ë¥¼ ê° ë ˆì´ë¸”ê³¼ ê·¸ì— ëŒ€ì‘í•˜ëŠ” ì‹ ë¢°ë„ì™€ í•¨ê»˜ ì¶œë ¥\n",
    "    for label, score in zip(result['labels'], result['scores']):\n",
    "        print(f\"ë ˆë²¨: {label} (ì‹ ë¢°ë„: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ì–´ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ NLI task í…ŒìŠ¤íŠ¸<br>\n",
    "ì˜ì–´ ë¬¸ì¥ì€ êµ¬ê¸€ ë²ˆì—­ê¸° ì‚¬ìš© "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence: There are currently no signs of murder, and police are investigating the exact circumstances of death.\n",
      "â†’ Prediction: CONTRADICTION (Confidence: 0.9164)\n",
      "\n",
      "Evidence: Former People Power Party lawmaker Jang Je-won was found dead.\n",
      "â†’ Prediction: NEUTRAL (Confidence: 0.8665)\n",
      "\n",
      "Evidence: It was reported that a suicide note believed to have been written by former lawmaker Jang was discovered at the scene.\n",
      "â†’ Prediction: NEUTRAL (Confidence: 0.7546)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# NLI íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "nli_pipeline = pipeline(\"text-classification\", model=\"roberta-large-mnli\")\n",
    "\n",
    "# claim = \"Coffee keeps you awake.\"\n",
    "# evidence_sentences = [\n",
    "#     \"Caffeine stimulates the central nervous system and reduces drowsiness.\",\n",
    "#     \"Drinking coffee can actually make you tired.\",\n",
    "#     \"The effect of waking up varies from person to person.\"\n",
    "#]\n",
    "\n",
    "claim = \"Rep. Jang Je-won was murdered\"\n",
    "evidence_sentences = [\n",
    "    \"There are currently no signs of murder, and police are investigating the exact circumstances of death.\",\n",
    "    \"Former People Power Party lawmaker Jang Je-won was found dead.\",\n",
    "    \"It was reported that a suicide note believed to have been written by former lawmaker Jang was discovered at the scene.\"\n",
    "]\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for evidence in evidence_sentences:\n",
    "    # NLI ì…ë ¥ì€ ë‘ ë¬¸ì¥ì„ í•¨ê»˜ ë„£ì–´ì•¼ í•¨ â†’ \"premise\", \"hypothesis\"\n",
    "    input_text = f\"{evidence} [SEP] {claim}\"\n",
    "    result = nli_pipeline(input_text)[0]\n",
    "\n",
    "    print(f\"Evidence: {evidence}\")\n",
    "    print(f\"â†’ Prediction: {result['label']} (Confidence: {result['score']:.4f})\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.21 ('transformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39d32efba01c30b0368d314f541dd447b1e0abc1c94139e3532a931796c9cc34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
